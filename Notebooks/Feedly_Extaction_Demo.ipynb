{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedly Data Extraction Demo\n",
    "\n",
    "Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JYddtNRdtwSW",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from feedly.client import *\n",
    "from feedly import *\n",
    "from newspaper import Article, ArticleException # http://newspaper.readthedocs.io/en/latest/\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "pd.set_option('max_rows',300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "J6F2HIOJs_Bl",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## IAP Crds\n",
    "TOKEN = \"A2zjasgZJawkY8etL3a9w1QP_BFLH7YcnaW_s-7kR7oU8Nkrz-ZY8spKj_rGuqYtyAJ4vYItikat_WS35cBCKA9jqYrbg_frpzLL_987_THA8BB4cXYfVGReSQMoScif6g7HI72_aKHYcheyqFVjObZX6QYiCZbrDAyzE1XvvvORiy8MjTSwRXQoX3in0_ywGYgFsfxJRA5M073PVSJJDv0Tv67JxC-GlvFRV3xiLqthS3Ed_8Qzztk:feedlydev\"\n",
    "FEEDLY_REDIRECT_URI = \"http://fabreadly.com/auth_callback\"\n",
    "FEEDLY_CLIENT_ID=\"d8f62d80-bd91-4b23-bdc3-c219d0489a26\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5GBsfMXqOI6m"
   },
   "source": [
    "# Load the Feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: [Feedly Documentation](https://developer.feedly.com/cloud/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QDjHGtvvzBRa",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Feedly\n",
    "feedaccess = TOKEN\n",
    "\n",
    "## Use url below to get the feed ids. \n",
    "myurl = 'https://cloud.feedly.com/v3/subscriptions'\n",
    "headers = {'Authorization': 'OAuth ' + feedaccess}\n",
    "res = requests.get(url=myurl, headers=headers)\n",
    "con = res.json()\n",
    "output = json.dumps(con , indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See all IAP Feeds and their IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the API you can pull specific feeds by ID, or you can pull everything. One issue is that IAP is also a content generator and actually pushes things to Feedly, so you also end up pulling that stuff. Anything marked EWS, or ewsdata.rightsindevelopment.org or a link to that site is an IAP generated entry, we need to filter these out. We should be able to do this faitly easily with the metadata that is available for each item. Other option is pull from a bunch of different feeds, but my guess is that filtering will actually be easier. \n",
    "\n",
    "Code below shows all the different feeds - the ALL feed is not listed but is coded as an option in the `pull_feed` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_feeds(feedaccess=feedaccess):\n",
    "    \"\"\"\n",
    "        Get the list of IAP feeds and the feed id - we need this when pulling the feed data. \n",
    "    \"\"\"\n",
    "    myurl = 'https://cloud.feedly.com/v3/subscriptions'\n",
    "    headers = {'Authorization': 'OAuth ' + feedaccess}\n",
    "    res = requests.get(url=myurl, headers=headers)\n",
    "    con = res.json()\n",
    "    output = json.dumps(con , indent=4)\n",
    "    df = pd.DataFrame([(c['title'] , c['categories'][0]['id']) for c in con])\n",
    "    df.columns = ['Title','id']\n",
    "    return df, con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, raw  = see_feeds(feedaccess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All - EWS</td>\n",
       "      <td>user/d8f62d80-bd91-4b23-bdc3-c219d0489a26/cate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EWS SA</td>\n",
       "      <td>user/d8f62d80-bd91-4b23-bdc3-c219d0489a26/cate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADB</td>\n",
       "      <td>user/d8f62d80-bd91-4b23-bdc3-c219d0489a26/cate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WB</td>\n",
       "      <td>user/d8f62d80-bd91-4b23-bdc3-c219d0489a26/cate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title: World Bank, Text: Loan</td>\n",
       "      <td>user/d8f62d80-bd91-4b23-bdc3-c219d0489a26/cate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Title  \\\n",
       "0                      All - EWS   \n",
       "1                         EWS SA   \n",
       "2                            ADB   \n",
       "3                             WB   \n",
       "4  Title: World Bank, Text: Loan   \n",
       "\n",
       "                                                  id  \n",
       "0  user/d8f62d80-bd91-4b23-bdc3-c219d0489a26/cate...  \n",
       "1  user/d8f62d80-bd91-4b23-bdc3-c219d0489a26/cate...  \n",
       "2  user/d8f62d80-bd91-4b23-bdc3-c219d0489a26/cate...  \n",
       "3  user/d8f62d80-bd91-4b23-bdc3-c219d0489a26/cate...  \n",
       "4  user/d8f62d80-bd91-4b23-bdc3-c219d0489a26/cate...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_feed(feed_id, feedcount, all_feeds=False,  feedaccess=feedaccess):\n",
    "    \"\"\"\n",
    "    Pull the feed information from the Feedly API and returns a list of pulled JSON objects. \n",
    "    Returns a list in case we are pulling more then 1000 items, then we have multiple JSON objects. \n",
    "    \n",
    "    feed_id: Id of the feed we want to pull from. (str)\n",
    "    feedcount: Target number of items to pull from the feed. (int)\n",
    "    all_feeds: If true then pulls all items in the IAP feed - value of feed_id will be ignored (Bool)\n",
    "    feedaccess: Token Information (str)\n",
    "    \"\"\"\n",
    "    \n",
    "    feedcount = str(feedcount)\n",
    "    current_count = 0\n",
    "    continuation_rounds = math.ceil(int(feedcount) / 1000.0)\n",
    "    json_data = []\n",
    "    continuation_id = None\n",
    "    if all_feeds:\n",
    "        feed_id = 'user/d8f62d80-bd91-4b23-bdc3-c219d0489a26/category/global.all'\n",
    "\n",
    "    for i in range(continuation_rounds):\n",
    "        print('Pulling Data - Round %s' % str(i+1))\n",
    "        myurl = \"http://cloud.feedly.com/v3/streams/contents?streamId=\" + feed_id + \"&count=\" + feedcount\n",
    "        \n",
    "        if continuation_id:\n",
    "            myurl += \"&continuation={}\".format(continuation_id)\n",
    "        headers = {'Authorization': 'OAuth ' + feedaccess}\n",
    "        res = requests.get(url=myurl, headers=headers)\n",
    "        con = res.json()\n",
    "        json_data.append(con)\n",
    "        \n",
    "        if int(feedcount) > 1000:\n",
    "            print(con.keys())\n",
    "            continuation_id = con['continuation']\n",
    "    \n",
    "    print('Complete')\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling Data - Round 1\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 2\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 3\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 4\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 5\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 6\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 7\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 8\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 9\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 10\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 11\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 12\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 13\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 14\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 15\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 16\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 17\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 18\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 19\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Pulling Data - Round 20\n",
      "dict_keys(['updated', 'continuation', 'items', 'id'])\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "pulled_json = pull_feed('',20000,all_feeds=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqMdKZCNOLnW"
   },
   "source": [
    "# Process the Feed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to a dataframe\n",
    "\n",
    "#TODO - Figure out what tags we need to preserve here - like from which news feed were they pulled - should be valuable for identifying the bank being mentioned.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SbMJxlMw6eBX",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def process_pulled_data(json_data):\n",
    "    df_data = []\n",
    "    \n",
    "    for grp in range(len(json_data)):\n",
    "        data = json_data[grp]\n",
    "        for i in range(len(data['items'])):\n",
    "\n",
    "            vals = data['items'][i]\n",
    "            article_data = []\n",
    "            article_data += [vals['fingerprint'], vals['published'], vals['title'],vals['alternate'][0]['href'],vals['categories'][0]['label']]\n",
    "            try:\n",
    "                article_data.append(vals['content']['content'])\n",
    "            except:\n",
    "                article_data.append(None)\n",
    "\n",
    "            try:\n",
    "                article_data.append(vals['summary']['content'])\n",
    "            except:\n",
    "                article_data.append(None)\n",
    "            df_data.append(article_data)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame(df_data, columns=None)\n",
    "    df.columns = ['article_id','published','title','url','feed_label','content','summary']\n",
    "    df.published = [datetime.datetime.fromtimestamp(i/1000.0) for i in df.published]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2df = process_pulled_data(pulled_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the Items "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove the EWS Posts - these are from IAP we don't need to process them **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2df['keep'] = [False if 'ews.rightsindevelopment.org' in i else True for i in json2df.url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     12098\n",
       "False     7902\n",
       "Name: keep, dtype: int64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json2df.keep.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2df = json2df[json2df.keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out File Uploads and other Non-Articles**\n",
    "\n",
    "It appears that if the `summary` field is empty the item is not an article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11036, 8)\n"
     ]
    }
   ],
   "source": [
    "json2df = json2df[json2df['summary'].notnull()]\n",
    "print(json2df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De-Dupe a Bit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_df = json2df.groupby(['article_id','title','url','keep']).agg({\n",
    "    'content':'min',\n",
    "    'summary':'min',\n",
    "    'published':'max',\n",
    "    'feed_label': lambda x: ','.join(set(x))}\n",
    "    ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9194, 8)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export - Pre Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_df = grp_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9194, 8)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>keep</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>published</th>\n",
       "      <th>feed_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7280</th>\n",
       "      <td>cd88676c</td>\n",
       "      <td>Tonga: World Bank Drone-Led Damage Assessments...</td>\n",
       "      <td>https://reliefweb.int/report/tonga/tonga-world...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;table border=\"0\" cellspacing=\"3\" cellpadding=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-22 00:03:16</td>\n",
       "      <td>NEWS WB- All Streams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8244</th>\n",
       "      <td>e72cf1f7</td>\n",
       "      <td>China's unstoppable momentum</td>\n",
       "      <td>https://gooruf.com/uk/news/2018/01/17/china-un...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;table border=\"0\" cellspacing=\"3\" cellpadding=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-17 06:56:52</td>\n",
       "      <td>NEWS AIIB - All Streams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>44fcbdb7</td>\n",
       "      <td>ADB agrees $375m loan for Madhya Pradesh irrig...</td>\n",
       "      <td>https://www.txfnews.com/Ticker/Redirect/84616f...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;table border=\"0\" cellspacing=\"3\" cellpadding=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-06-01 03:32:41</td>\n",
       "      <td>NEWS ADB - All Streams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7052</th>\n",
       "      <td>c77bc305</td>\n",
       "      <td>Ethiopia: European Investment Bank Injects €3m...</td>\n",
       "      <td>http://allafrica.com/stories/201802060591.html</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;table border=\"0\" cellspacing=\"3\" cellpadding=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-06 06:46:17</td>\n",
       "      <td>NEWS EIB - All streams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>b6e91d1e</td>\n",
       "      <td>AIIB approves two new applicants, expands memb...</td>\n",
       "      <td>http://www.xinhuanet.com/english/2018-05/02/c_...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;table border=\"0\" cellspacing=\"3\" cellpadding=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-02 01:58:00</td>\n",
       "      <td>NEWS AIIB - All Streams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id                                              title  \\\n",
       "7280   cd88676c  Tonga: World Bank Drone-Led Damage Assessments...   \n",
       "8244   e72cf1f7                       China's unstoppable momentum   \n",
       "2058   44fcbdb7  ADB agrees $375m loan for Madhya Pradesh irrig...   \n",
       "7052   c77bc305  Ethiopia: European Investment Bank Injects €3m...   \n",
       "6403   b6e91d1e  AIIB approves two new applicants, expands memb...   \n",
       "\n",
       "                                                    url  keep  \\\n",
       "7280  https://reliefweb.int/report/tonga/tonga-world...  True   \n",
       "8244  https://gooruf.com/uk/news/2018/01/17/china-un...  True   \n",
       "2058  https://www.txfnews.com/Ticker/Redirect/84616f...  True   \n",
       "7052     http://allafrica.com/stories/201802060591.html  True   \n",
       "6403  http://www.xinhuanet.com/english/2018-05/02/c_...  True   \n",
       "\n",
       "                                                summary content  \\\n",
       "7280  <table border=\"0\" cellspacing=\"3\" cellpadding=...     NaN   \n",
       "8244  <table border=\"0\" cellspacing=\"3\" cellpadding=...     NaN   \n",
       "2058  <table border=\"0\" cellspacing=\"3\" cellpadding=...     NaN   \n",
       "7052  <table border=\"0\" cellspacing=\"3\" cellpadding=...     NaN   \n",
       "6403  <table border=\"0\" cellspacing=\"3\" cellpadding=...     NaN   \n",
       "\n",
       "               published               feed_label  \n",
       "7280 2018-02-22 00:03:16     NEWS WB- All Streams  \n",
       "8244 2018-01-17 06:56:52  NEWS AIIB - All Streams  \n",
       "2058 2018-06-01 03:32:41   NEWS ADB - All Streams  \n",
       "7052 2018-02-06 06:46:17   NEWS EIB - All streams  \n",
       "6403 2018-05-02 01:58:00  NEWS AIIB - All Streams  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_df[['article_id','published','title','url','feed_label']].to_csv('../Temp_Output/article20k_pull4labeling.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** - This is Slow - so may need to run in batches or overnight, or both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('../Temp_Output/article_cache.pkl', 'rb') as file:\n",
    "        cache = pickle.load(file)\n",
    "except:\n",
    "    cache = {}\n",
    "    print('Creating New Cache.. Is this Correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_via_Article(url, article_id):\n",
    "    \"\"\"\n",
    "    Returns scraped article content - using the newspaper3k module (http://newspaper.readthedocs.io/en/latest/)\n",
    "    \"\"\"\n",
    "    \n",
    "    global cache\n",
    "    \n",
    "    if article_id not in cache:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        try:\n",
    "            article.parse()\n",
    "        except ArticleException:  \n",
    "            print('Encountered Exception',url)\n",
    "            article.download()\n",
    "            print('sleeping')\n",
    "            sleep(10)\n",
    "            try:\n",
    "                article.parse()\n",
    "            except ArticleException:  #Messy code here but just getting this working \n",
    "                print('Article Not Downloaded')\n",
    "                return np.nan\n",
    "        ## Now Process Article \n",
    "        article.nlp()\n",
    "        cache[article_id] = (article.text, article.keywords)\n",
    "        return None\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.adb.org/node/415051?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+adb_news+%28ADB.org+News+Releases+RSS%29 on URL http://feedproxy.google.com/~r/adb_news/~3/-LPJT1oP4-w/415051\n",
      "Encountered Exception http://feedproxy.google.com/~r/adb_news/~3/-LPJT1oP4-w/415051\n",
      "sleeping\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.adb.org/node/415051?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+adb_news+%28ADB.org+News+Releases+RSS%29 on URL http://feedproxy.google.com/~r/adb_news/~3/-LPJT1oP4-w/415051\n",
      "Article Not Downloaded\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "for cnt, idx in enumerate(grp_df.index):\n",
    "    if cnt%25 == 0:\n",
    "        print(cnt)\n",
    "    row = grp_df.loc[idx]\n",
    "    get_text_via_Article(row['url'],row['article_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../Temp_Output/article_cache.pkl', 'wb') as file:\n",
    "    pickle.dump( cache, file)\n",
    "test_df['scraped_content'] = test_df['article_id'].map(cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Results and add in Some Language Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IAP only has content in English currently so tagging articles in other languages is likely too complicated at this time as it wold also involve a translation step. Therefore we may want to filter out non English language articles. \n",
    "\n",
    "Newspaper 3k has this functionality - but it is slow - this work pretty fast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect_langs\n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[en:0.9999952972346535]\n",
      "European Union institution the European Investment Bank (EIB) has renewed its partnership with French port Marseille Fos under a €50 million funding agreement to support five key development projects.\n",
      "\n",
      "\n",
      "\n",
      "The projects, which require a total investment of €136 million, include connecting the two exist \n",
      "\n",
      "*******\n",
      "[en:0.9999991131684797]\n",
      "India signed a USD 500 million (Rs 3,371 crore) loan pact with World Bank today to provide additional financing for PMGSY rural road projects.\n",
      "\n",
      "The loan has a 3-year grace period, and a maturity of 10 years, the finance Ministry said in a release.\n",
      "\n",
      "It will provide additional financing for the Pradha \n",
      "\n",
      "*******\n",
      "[en:0.9999952599411848]\n",
      "9700 Jamaican families enrolled in study\n",
      "\n",
      "Data on fathers’ impact on child development collected for the first time\n",
      "\n",
      "The UWI JA KIDS Birth Cohort Study Research Team will host a conference at the University of the West Indies from May 31 to June 1 to share ground-breaking findings from their seven-y \n",
      "\n",
      "*******\n",
      "[en:0.9999973036038267]\n",
      "WASHINGTON, United States, Thursday May 31, 2018 – Latin America and the Caribbean could add an additional $11 billion in annual trade flows by blending 33 separate agreements into a single regional free trade bloc, according to a study by the Inter-American Development Bank (IDB) .\n",
      "\n",
      "‘Connecting the \n",
      "\n",
      "*******\n",
      "[en:0.9999978397052093]\n",
      "The European Investment Bank (EIB) on Thursday confirmed €35 million in new financing for the expansion of strategic oil reserves in Cyprus.\n",
      "\n",
      "Management of strategic oil reserves in Cyprus is to be transformed through construction of a new emergency energy facility enabling Cyprus to hold one month’ \n",
      "\n",
      "*******\n"
     ]
    }
   ],
   "source": [
    "for i in test_df.head().scraped_content:\n",
    "    try:\n",
    "        print(detect_langs(i))\n",
    "    except LangDetectException:  \n",
    "        continue\n",
    "    print(i[0:300],\n",
    "         '\\n')\n",
    "    print ('*******')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cY_u0Azs8IAD",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Detect Language\n",
    "2. Error Test on larger set\n",
    "3. Manually verify extact is generally correct \n",
    "4. Extract article content for all articles in DataDive dataset (Could take a long time)\n",
    "5. Method for Identifying articles previously scraped (we need a unique identifier so we can only scrape new articles in the future) -- This is just something to keep in mind. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "feedly_test.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "my_py_3",
   "language": "python",
   "name": "my_py_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "nav_menu": {
    "height": "64px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
